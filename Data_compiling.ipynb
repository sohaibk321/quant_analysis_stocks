{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import bs4 as bs\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.dates import date2num, DayLocator, DateFormatter\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader as web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Using data from the S&P 500, I want to analyze the companies to see if I can find some surface level patterns to group companies together. After which, I will use historical data collected from yahoo finance to set up technical indicators and conduct quantitative analysis to find any useful patterns to set up buy and sell signals. \n",
    "\n",
    "I'll start by scraping the S&P 500 companies list from the wikipedia page and load in the tickers through yahoo finance. After which, I will cluster their returns on top of other indicators such as sectory and market cap to find any salient groupings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2017-01-01'\n",
    "end = '2019-03-25'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately somehwere along the way, the data from yahoo finance stopped loading due to errors in the API, then I switched to Quandl. However, quandl also started giving missing data quite often when there should have been data there as well. Due to this, I am reverting to using a precompiled source of S&P500 company data from kaggle which ranges from 2013 to Feb 2018. For the sake of simplicity, I will use this to make the dataset for the clustering portion, but at one point this code worked as intended. If fixes are made to these APIs, then they can be used to scrape custom csv files with differing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all the company tickers from the S&P 500\n",
    "def save_sp500_companies():\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[1].text\n",
    "        #ticker = ticker.replace('.','') Kaggle data accounts for dot notation used in stock listings\n",
    "        tickers.append(ticker)\n",
    "    # saves the data into a local format so I don't have to reload it everytime\n",
    "    with open('sp500tickers.pickle', 'wb') as f:\n",
    "        pickle.dump(tickers, f)\n",
    "        \n",
    "    print(tickers)\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM already exists.\n",
      "ABT already exists.\n",
      "ABBV already exists.\n",
      "ABMD already exists.\n",
      "ACN already exists.\n",
      "ATVI already exists.\n",
      "ADBE already exists.\n",
      "AMD already exists.\n",
      "AAP already exists.\n",
      "AES already exists.\n",
      "AMG already exists.\n",
      "AFL already exists.\n",
      "A already exists.\n",
      "APD already exists.\n",
      "AKAM already exists.\n",
      "ALK already exists.\n",
      "ALB already exists.\n",
      "ARE already exists.\n",
      "ALXN already exists.\n",
      "ALGN already exists.\n",
      "ALLE already exists.\n",
      "AGN already exists.\n",
      "ADS already exists.\n",
      "LNT already exists.\n",
      "ALL already exists.\n",
      "GOOGL already exists.\n",
      "GOOG already exists.\n",
      "MO already exists.\n",
      "AMZN already exists.\n",
      "AEE already exists.\n",
      "AAL already exists.\n",
      "AEP already exists.\n",
      "AXP already exists.\n",
      "AIG already exists.\n",
      "AMT already exists.\n",
      "AWK already exists.\n",
      "AMP already exists.\n",
      "ABC already exists.\n",
      "AME already exists.\n",
      "AMGN already exists.\n",
      "APH already exists.\n",
      "APC already exists.\n",
      "ADI already exists.\n",
      "ANSS already exists.\n",
      "ANTM already exists.\n",
      "AON already exists.\n",
      "AOS already exists.\n",
      "APA already exists.\n",
      "AIV already exists.\n",
      "AAPL already exists.\n",
      "AMAT already exists.\n",
      "APTV already exists.\n",
      "ADM already exists.\n",
      "ARNC already exists.\n",
      "ANET not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/ANET.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "AJG already exists.\n",
      "AIZ already exists.\n",
      "ATO already exists.\n",
      "T already exists.\n",
      "ADSK already exists.\n",
      "ADP already exists.\n",
      "AZO already exists.\n",
      "AVB already exists.\n",
      "AVY already exists.\n",
      "BHGE already exists.\n",
      "BLL already exists.\n",
      "BAC already exists.\n",
      "BK already exists.\n",
      "BAX already exists.\n",
      "BBT already exists.\n",
      "BDX already exists.\n",
      "BRK.B not loading.  Symbol 'WIKI/BRK.B' must conform to Quandl convention 'DB/SYM'\n",
      "BBY already exists.\n",
      "BIIB already exists.\n",
      "BLK already exists.\n",
      "HRB already exists.\n",
      "BA already exists.\n",
      "BKNG already exists.\n",
      "BWA already exists.\n",
      "BXP already exists.\n",
      "BSX already exists.\n",
      "BHF already exists.\n",
      "BMY already exists.\n",
      "AVGO already exists.\n",
      "BR already exists.\n",
      "BF.B not loading.  Symbol 'WIKI/BF.B' must conform to Quandl convention 'DB/SYM'\n",
      "CHRW already exists.\n",
      "COG already exists.\n",
      "CDNS already exists.\n",
      "CPB already exists.\n",
      "COF already exists.\n",
      "CPRI not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/CPRI.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "CAH already exists.\n",
      "KMX already exists.\n",
      "CCL already exists.\n",
      "CAT already exists.\n",
      "CBOE already exists.\n",
      "CBRE already exists.\n",
      "CBS already exists.\n",
      "CE already exists.\n",
      "CELG already exists.\n",
      "CNC already exists.\n",
      "CNP already exists.\n",
      "CTL already exists.\n",
      "CERN already exists.\n",
      "CF already exists.\n",
      "SCHW already exists.\n",
      "CHTR already exists.\n",
      "CVX already exists.\n",
      "CMG already exists.\n",
      "CB already exists.\n",
      "CHD already exists.\n",
      "CI already exists.\n",
      "XEC already exists.\n",
      "CINF already exists.\n",
      "CTAS already exists.\n",
      "CSCO already exists.\n",
      "C already exists.\n",
      "CFG already exists.\n",
      "CTXS already exists.\n",
      "CLX already exists.\n",
      "CME already exists.\n",
      "CMS already exists.\n",
      "KO already exists.\n",
      "CTSH already exists.\n",
      "CL already exists.\n",
      "CMCSA already exists.\n",
      "CMA already exists.\n",
      "CAG already exists.\n",
      "CXO already exists.\n",
      "COP already exists.\n",
      "ED already exists.\n",
      "STZ already exists.\n",
      "COO already exists.\n",
      "CPRT already exists.\n",
      "GLW already exists.\n",
      "COST already exists.\n",
      "COTY already exists.\n",
      "CCI already exists.\n",
      "CSX already exists.\n",
      "CMI already exists.\n",
      "CVS already exists.\n",
      "DHI already exists.\n",
      "DHR already exists.\n",
      "DRI already exists.\n",
      "DVA already exists.\n",
      "DE already exists.\n",
      "DAL already exists.\n",
      "XRAY already exists.\n",
      "DVN already exists.\n",
      "FANG already exists.\n",
      "DLR already exists.\n",
      "DFS already exists.\n",
      "DISCA already exists.\n",
      "DISCK already exists.\n",
      "DISH already exists.\n",
      "DG already exists.\n",
      "DLTR already exists.\n",
      "D already exists.\n",
      "DOV already exists.\n",
      "DWDP already exists.\n",
      "DTE already exists.\n",
      "DRE already exists.\n",
      "DUK already exists.\n",
      "DXC already exists.\n",
      "ETFC already exists.\n",
      "EMN already exists.\n",
      "ETN already exists.\n",
      "EBAY already exists.\n",
      "ECL already exists.\n",
      "EIX already exists.\n",
      "EW already exists.\n",
      "EA already exists.\n",
      "EMR already exists.\n",
      "ETR already exists.\n",
      "EOG already exists.\n",
      "EFX already exists.\n",
      "EQIX already exists.\n",
      "EQR already exists.\n",
      "ESS already exists.\n",
      "EL already exists.\n",
      "EVRG not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/EVRG.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "ES already exists.\n",
      "RE already exists.\n",
      "EXC already exists.\n",
      "EXPE already exists.\n",
      "EXPD already exists.\n",
      "EXR already exists.\n",
      "XOM already exists.\n",
      "FFIV already exists.\n",
      "FB already exists.\n",
      "FAST already exists.\n",
      "FRT already exists.\n",
      "FDX already exists.\n",
      "FIS already exists.\n",
      "FITB already exists.\n",
      "FE already exists.\n",
      "FRC already exists.\n",
      "FISV already exists.\n",
      "FLT already exists.\n",
      "FLIR already exists.\n",
      "FLS already exists.\n",
      "FLR already exists.\n",
      "FMC already exists.\n",
      "FL already exists.\n",
      "F already exists.\n",
      "FTNT already exists.\n",
      "FTV already exists.\n",
      "FBHS already exists.\n",
      "BEN already exists.\n",
      "FCX already exists.\n",
      "GPS already exists.\n",
      "GRMN already exists.\n",
      "IT already exists.\n",
      "GD already exists.\n",
      "GE already exists.\n",
      "GIS already exists.\n",
      "GM already exists.\n",
      "GPC already exists.\n",
      "GILD already exists.\n",
      "GPN already exists.\n",
      "GS already exists.\n",
      "GWW already exists.\n",
      "HAL already exists.\n",
      "HBI already exists.\n",
      "HOG already exists.\n",
      "HRS already exists.\n",
      "HIG already exists.\n",
      "HAS already exists.\n",
      "HCA already exists.\n",
      "HCP already exists.\n",
      "HP already exists.\n",
      "HSIC already exists.\n",
      "HSY already exists.\n",
      "HES already exists.\n",
      "HPE already exists.\n",
      "HLT already exists.\n",
      "HFC already exists.\n",
      "HOLX already exists.\n",
      "HD already exists.\n",
      "HON already exists.\n",
      "HRL already exists.\n",
      "HST already exists.\n",
      "HPQ already exists.\n",
      "HUM already exists.\n",
      "HBAN already exists.\n",
      "HII already exists.\n",
      "IDXX already exists.\n",
      "INFO already exists.\n",
      "ITW already exists.\n",
      "ILMN already exists.\n",
      "IR already exists.\n",
      "INTC already exists.\n",
      "ICE already exists.\n",
      "IBM already exists.\n",
      "INCY already exists.\n",
      "IP already exists.\n",
      "IPG already exists.\n",
      "IFF already exists.\n",
      "ISRG already exists.\n",
      "IVZ already exists.\n",
      "IPGP already exists.\n",
      "IQV already exists.\n",
      "IRM already exists.\n",
      "JKHY already exists.\n",
      "JEC already exists.\n",
      "JBHT already exists.\n",
      "JEF not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/JEF.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "SJM already exists.\n",
      "JNJ already exists.\n",
      "JCI already exists.\n",
      "JPM already exists.\n",
      "JNPR already exists.\n",
      "KSU already exists.\n",
      "K already exists.\n",
      "KEY already exists.\n",
      "KEYS not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/KEYS.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "KMB already exists.\n",
      "KIM already exists.\n",
      "KMI already exists.\n",
      "KLAC already exists.\n",
      "KSS already exists.\n",
      "KHC already exists.\n",
      "KR already exists.\n",
      "LB already exists.\n",
      "LLL already exists.\n",
      "LH already exists.\n",
      "LRCX already exists.\n",
      "LW not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/LW.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "LEG already exists.\n",
      "LEN already exists.\n",
      "LLY already exists.\n",
      "LNC already exists.\n",
      "LIN not loading.  Unable to read URL: https://www.quandl.com/api/v3/datasets/WIKI/LIN.csv?order=asc&end_date=2019-03-25&start_date=2017-01-01\n",
      "Response Text:\n",
      "b'code,message\\nQECx02,You have submitted an incorrect Quandl code. Please check your Quandl codes and try again.\\n'\n",
      "LMT already exists.\n",
      "L already exists.\n",
      "LOW already exists.\n",
      "LYB already exists.\n",
      "MTB already exists.\n",
      "MAC already exists.\n",
      "M already exists.\n",
      "MRO already exists.\n",
      "MPC already exists.\n",
      "MAR already exists.\n",
      "MMC already exists.\n",
      "MLM already exists.\n",
      "MAS already exists.\n",
      "MA already exists.\n",
      "MAT already exists.\n",
      "MKC already exists.\n",
      "MXIM already exists.\n",
      "MCD already exists.\n",
      "MCK already exists.\n",
      "MDT already exists.\n",
      "MRK already exists.\n",
      "MET already exists.\n",
      "MTD already exists.\n",
      "MGM already exists.\n",
      "MCHP already exists.\n",
      "MU already exists.\n",
      "MSFT already exists.\n",
      "MAA already exists.\n",
      "MHK already exists.\n",
      "TAP already exists.\n",
      "MDLZ already exists.\n",
      "MNST already exists.\n",
      "MCO already exists.\n",
      "MS already exists.\n",
      "MOS already exists.\n",
      "MSI already exists.\n",
      "MSCI already exists.\n",
      "MYL already exists.\n",
      "NDAQ already exists.\n",
      "NOV already exists.\n",
      "NKTR already exists.\n",
      "NTAP already exists.\n",
      "NFLX already exists.\n",
      "NWL already exists.\n",
      "NEM already exists.\n",
      "NWSA already exists.\n",
      "NWS already exists.\n",
      "NEE already exists.\n",
      "NLSN already exists.\n",
      "NKE already exists.\n",
      "NI already exists.\n",
      "NBL already exists.\n",
      "JWN already exists.\n",
      "NSC already exists.\n",
      "NTRS already exists.\n",
      "NOC already exists.\n",
      "NCLH already exists.\n",
      "NRG already exists.\n",
      "NUE already exists.\n",
      "NVDA already exists.\n",
      "ORLY already exists.\n",
      "OXY already exists.\n",
      "OMC already exists.\n",
      "OKE already exists.\n",
      "ORCL already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKG already exists.\n",
      "PH already exists.\n",
      "PAYX already exists.\n",
      "PYPL already exists.\n",
      "PNR already exists.\n",
      "PBCT already exists.\n",
      "PEP already exists.\n",
      "PKI already exists.\n",
      "PRGO already exists.\n",
      "PFE already exists.\n",
      "PM already exists.\n",
      "PSX already exists.\n",
      "PNW already exists.\n",
      "PXD already exists.\n",
      "PNC already exists.\n",
      "RL already exists.\n",
      "PPG already exists.\n",
      "PPL already exists.\n",
      "PFG already exists.\n",
      "PG already exists.\n",
      "PGR already exists.\n",
      "PLD already exists.\n",
      "PRU already exists.\n",
      "PEG already exists.\n",
      "PSA already exists.\n",
      "PHM already exists.\n",
      "PVH already exists.\n",
      "QRVO already exists.\n",
      "PWR already exists.\n",
      "QCOM already exists.\n",
      "DGX already exists.\n",
      "RJF already exists.\n",
      "RTN already exists.\n",
      "O already exists.\n",
      "RHT already exists.\n",
      "REG already exists.\n",
      "REGN already exists.\n",
      "RF already exists.\n",
      "RSG already exists.\n",
      "RMD already exists.\n",
      "RHI already exists.\n",
      "ROK already exists.\n",
      "ROL already exists.\n",
      "ROST already exists.\n",
      "RCL already exists.\n",
      "CRM already exists.\n",
      "SBAC already exists.\n",
      "SLB already exists.\n",
      "STX already exists.\n",
      "SEE already exists.\n",
      "SRE already exists.\n",
      "SHW already exists.\n",
      "SPG already exists.\n",
      "SWKS already exists.\n",
      "SLG already exists.\n",
      "SNA already exists.\n",
      "SO already exists.\n",
      "LUV already exists.\n",
      "SPGI already exists.\n",
      "SWK already exists.\n",
      "SBUX already exists.\n",
      "STT already exists.\n",
      "SYK already exists.\n",
      "STI already exists.\n",
      "SIVB already exists.\n",
      "SYMC already exists.\n",
      "SYF already exists.\n",
      "SNPS already exists.\n",
      "SYY already exists.\n",
      "TROW already exists.\n",
      "TTWO already exists.\n",
      "TPR already exists.\n",
      "TGT already exists.\n",
      "TEL already exists.\n",
      "FTI already exists.\n",
      "TFX already exists.\n",
      "TXN already exists.\n",
      "TXT already exists.\n",
      "TMO already exists.\n",
      "TIF already exists.\n",
      "TWTR already exists.\n",
      "TJX already exists.\n",
      "TMK already exists.\n",
      "TSS already exists.\n",
      "TSCO already exists.\n",
      "TDG already exists.\n",
      "TRV already exists.\n",
      "TRIP already exists.\n",
      "FOXA already exists.\n",
      "FOX already exists.\n",
      "TSN already exists.\n",
      "UDR already exists.\n",
      "ULTA already exists.\n",
      "USB already exists.\n",
      "UAA already exists.\n",
      "UA already exists.\n",
      "UNP already exists.\n",
      "UAL already exists.\n",
      "UNH already exists.\n",
      "UPS already exists.\n",
      "URI already exists.\n",
      "UTX already exists.\n",
      "UHS already exists.\n",
      "UNM already exists.\n",
      "VFC already exists.\n",
      "VLO already exists.\n",
      "VAR already exists.\n",
      "VTR already exists.\n",
      "VRSN already exists.\n",
      "VRSK already exists.\n",
      "VZ already exists.\n",
      "VRTX already exists.\n",
      "VIAB already exists.\n",
      "V already exists.\n",
      "VNO already exists.\n",
      "VMC already exists.\n",
      "WAB already exists.\n",
      "WMT already exists.\n",
      "WBA already exists.\n",
      "DIS already exists.\n",
      "WM already exists.\n",
      "WAT already exists.\n",
      "WEC already exists.\n",
      "WCG already exists.\n",
      "WFC already exists.\n",
      "WELL already exists.\n",
      "WDC already exists.\n",
      "WU already exists.\n",
      "WRK already exists.\n",
      "WY already exists.\n",
      "WHR already exists.\n",
      "WMB already exists.\n",
      "WLTW already exists.\n",
      "WYNN already exists.\n",
      "XEL already exists.\n",
      "XRX already exists.\n",
      "XLNX already exists.\n",
      "XYL already exists.\n",
      "YUM already exists.\n",
      "ZBH already exists.\n",
      "ZION already exists.\n",
      "ZTS already exists.\n"
     ]
    }
   ],
   "source": [
    "def get_data_quandl(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_companies()        \n",
    "    else:\n",
    "        with open('sp500tickers.pickle', 'rb') as f:\n",
    "            tickers = pickle.load(f)\n",
    "            \n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "# load in the tickers and make them into one dataframe\n",
    "    for ticker in tickers[:]:\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            try:\n",
    "                df = web.DataReader('WIKI/{}'.format(ticker), 'quandl', start, end,access_key='qaB2Gz6zLzLLoHroWJUF').loc[::-1, ['AdjClose', 'Volume']]\n",
    "                df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "            except Exception as e:\n",
    "                print(\"{} not loading. \".format(ticker), e)\n",
    "        else:\n",
    "            print(\"{} already exists.\".format(ticker))\n",
    "            \n",
    "get_data_quandl(reload_sp500=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "ANET not present. File b'stock_dfs/ANET.csv' does not exist\n",
      "60\n",
      "70\n",
      "BRK.B not present. File b'stock_dfs/BRK.B.csv' does not exist\n",
      "80\n",
      "BF.B not present. File b'stock_dfs/BF.B.csv' does not exist\n",
      "90\n",
      "CPRI not present. File b'stock_dfs/CPRI.csv' does not exist\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "EVRG not present. File b'stock_dfs/EVRG.csv' does not exist\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "JEF not present. File b'stock_dfs/JEF.csv' does not exist\n",
      "270\n",
      "KEYS not present. File b'stock_dfs/KEYS.csv' does not exist\n",
      "280\n",
      "LW not present. File b'stock_dfs/LW.csv' does not exist\n",
      "290\n",
      "LIN not present. File b'stock_dfs/LIN.csv' does not exist\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "                   MMM        ABT       ABBV    ABMD         ACN       ATVI  \\\n",
      "2017-01-03  174.831943  38.170443  60.192574  112.36  114.153742  36.420423   \n",
      "2017-01-04  175.097063  38.473461  61.041308  115.74  114.428197  37.136109   \n",
      "2017-01-05  174.498088  38.805803  61.504254  114.81  112.712852  37.712633   \n",
      "2017-01-06  175.008690  39.861477  61.523543  115.42  113.996910  37.682813   \n",
      "2017-01-09  174.066041  39.822378  61.928620  117.11  112.722654  37.474071   \n",
      "\n",
      "              ADBE    AMD         AAP        AES    ...            WLTW  \\\n",
      "2017-01-03  103.48  11.43  170.338116  11.168091    ...      121.886431   \n",
      "2017-01-04  104.14  11.43  171.735967  11.072310    ...      123.389736   \n",
      "2017-01-05  105.91  11.24  171.616151  10.928638    ...      124.576556   \n",
      "2017-01-06  108.30  11.32  169.369605  11.321341    ...      125.387550   \n",
      "2017-01-09  108.57  11.49  169.269759  11.043575    ...      124.626007   \n",
      "\n",
      "                 WYNN        XEL        XRX       XLNX        XYL        YUM  \\\n",
      "2017-01-03  86.053393  39.687774  27.064752  58.097192  49.016947  62.371932   \n",
      "2017-01-04  88.828039  39.863643  28.086063  57.674274  49.747512  62.598883   \n",
      "2017-01-05  89.969383  39.863643  27.968220  56.975967  49.293377  62.806099   \n",
      "2017-01-06  90.943461  39.980889  27.536126  58.077522  48.947840  63.565890   \n",
      "2017-01-09  91.258314  39.375118  27.379002  58.087357  48.740517  63.743503   \n",
      "\n",
      "                   ZBH       ZION        ZTS  \n",
      "2017-01-03  102.715814  42.904783  53.287880  \n",
      "2017-01-04  103.660167  43.520831  53.804949  \n",
      "2017-01-05  104.326185  42.815357  53.625963  \n",
      "2017-01-06  104.336126  43.093572  53.795005  \n",
      "2017-01-09  106.364000  42.626568  53.645851  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    }
   ],
   "source": [
    "def compile_dfs():\n",
    "    with open('sp500tickers.pickle', 'rb') as f:\n",
    "        tickers = pickle.load(f)\n",
    "    prices = []\n",
    "    prices_df = pd.DataFrame()\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        if count % 10 == 0 :\n",
    "            print(count)\n",
    "        try:\n",
    "            df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "            df = df.rename(columns={'AdjClose': ticker})\n",
    "            df.index = df.Date\n",
    "            df.drop('Date', axis=1, inplace=True)\n",
    "            df = df[ticker]\n",
    "        except Exception as e:\n",
    "            print('{} not present.'.format(ticker), e)\n",
    "        \n",
    "        prices.append(df)\n",
    "        prices_df = pd.concat([prices_df, df], axis=1)\n",
    "            \n",
    "    print(prices_df.head())\n",
    "    prices_df.to_csv('sp500_close_joined.csv')\n",
    "        \n",
    "compile_dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset from kaggle data if yahoo finance is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI', 'ADBE', 'AMD', 'AAP', 'AES', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'APC', 'ADI', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'ANET', 'AJG', 'AIZ', 'ATO', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BHGE', 'BLL', 'BAC', 'BK', 'BAX', 'BBT', 'BDX', 'BRK.B', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BHF', 'BMY', 'AVGO', 'BR', 'BF.B', 'CHRW', 'COG', 'CDNS', 'CPB', 'COF', 'CPRI', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CE', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'COO', 'CPRT', 'GLW', 'COST', 'COTY', 'CCI', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'FANG', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DWDP', 'DTE', 'DRE', 'DUK', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EOG', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'EVRG', 'ES', 'RE', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FRC', 'FISV', 'FLT', 'FLIR', 'FLS', 'FLR', 'FMC', 'FL', 'F', 'FTNT', 'FTV', 'FBHS', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GS', 'GWW', 'HAL', 'HBI', 'HOG', 'HRS', 'HIG', 'HAS', 'HCA', 'HCP', 'HP', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HFC', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IDXX', 'INFO', 'ITW', 'ILMN', 'IR', 'INTC', 'ICE', 'IBM', 'INCY', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JKHY', 'JEC', 'JBHT', 'JEF', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LLL', 'LH', 'LRCX', 'LW', 'LEG', 'LEN', 'LLY', 'LNC', 'LIN', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MAT', 'MKC', 'MXIM', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'MYL', 'NDAQ', 'NOV', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'RL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RJF', 'RTN', 'O', 'RHT', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'CRM', 'SBAC', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SPGI', 'SWK', 'SBUX', 'STT', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TFX', 'TXN', 'TXT', 'TMO', 'TIF', 'TWTR', 'TJX', 'TMK', 'TSS', 'TSCO', 'TDG', 'TRV', 'TRIP', 'FOXA', 'FOX', 'TSN', 'UDR', 'ULTA', 'USB', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WAB', 'WMT', 'WBA', 'DIS', 'WM', 'WAT', 'WEC', 'WCG', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n",
      "0\n",
      "ABMD not loaded File b'individual_stocks_5yr/ABMD_data.csv' does not exist\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "ANET not loaded File b'individual_stocks_5yr/ANET_data.csv' does not exist\n",
      "ATO not loaded File b'individual_stocks_5yr/ATO_data.csv' does not exist\n",
      "60\n",
      "70\n",
      "BKNG not loaded File b'individual_stocks_5yr/BKNG_data.csv' does not exist\n",
      "80\n",
      "BR not loaded File b'individual_stocks_5yr/BR_data.csv' does not exist\n",
      "90\n",
      "CPRI not loaded File b'individual_stocks_5yr/CPRI_data.csv' does not exist\n",
      "CBRE not loaded File b'individual_stocks_5yr/CBRE_data.csv' does not exist\n",
      "CE not loaded File b'individual_stocks_5yr/CE_data.csv' does not exist\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "CPRT not loaded File b'individual_stocks_5yr/CPRT_data.csv' does not exist\n",
      "140\n",
      "150\n",
      "FANG not loaded File b'individual_stocks_5yr/FANG_data.csv' does not exist\n",
      "160\n",
      "170\n",
      "180\n",
      "EVRG not loaded File b'individual_stocks_5yr/EVRG_data.csv' does not exist\n",
      "190\n",
      "FRC not loaded File b'individual_stocks_5yr/FRC_data.csv' does not exist\n",
      "FLT not loaded File b'individual_stocks_5yr/FLT_data.csv' does not exist\n",
      "200\n",
      "FTNT not loaded File b'individual_stocks_5yr/FTNT_data.csv' does not exist\n",
      "210\n",
      "220\n",
      "230\n",
      "HFC not loaded File b'individual_stocks_5yr/HFC_data.csv' does not exist\n",
      "240\n",
      "250\n",
      "260\n",
      "IPGP not loaded File b'individual_stocks_5yr/IPGP_data.csv' does not exist\n",
      "JKHY not loaded File b'individual_stocks_5yr/JKHY_data.csv' does not exist\n",
      "JEF not loaded File b'individual_stocks_5yr/JEF_data.csv' does not exist\n",
      "270\n",
      "KEYS not loaded File b'individual_stocks_5yr/KEYS_data.csv' does not exist\n",
      "280\n",
      "LW not loaded File b'individual_stocks_5yr/LW_data.csv' does not exist\n",
      "290\n",
      "LIN not loaded File b'individual_stocks_5yr/LIN_data.csv' does not exist\n",
      "300\n",
      "310\n",
      "MXIM not loaded File b'individual_stocks_5yr/MXIM_data.csv' does not exist\n",
      "320\n",
      "330\n",
      "MSCI not loaded File b'individual_stocks_5yr/MSCI_data.csv' does not exist\n",
      "NKTR not loaded File b'individual_stocks_5yr/NKTR_data.csv' does not exist\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "ROL not loaded File b'individual_stocks_5yr/ROL_data.csv' does not exist\n",
      "410\n",
      "420\n",
      "SIVB not loaded File b'individual_stocks_5yr/SIVB_data.csv' does not exist\n",
      "430\n",
      "TTWO not loaded File b'individual_stocks_5yr/TTWO_data.csv' does not exist\n",
      "TFX not loaded File b'individual_stocks_5yr/TFX_data.csv' does not exist\n",
      "440\n",
      "TWTR not loaded File b'individual_stocks_5yr/TWTR_data.csv' does not exist\n",
      "450\n",
      "460\n",
      "470\n",
      "WAB not loaded File b'individual_stocks_5yr/WAB_data.csv' does not exist\n",
      "480\n",
      "WCG not loaded File b'individual_stocks_5yr/WCG_data.csv' does not exist\n",
      "WELL not loaded File b'individual_stocks_5yr/WELL_data.csv' does not exist\n",
      "490\n",
      "500\n",
      "               MMM    ABT   ABBV   ABBV    ACN   ATVI   ADBE   AMD    AAP  \\\n",
      "date                                                                        \n",
      "2013-02-08  102.66  34.41  36.25  36.25  73.31  13.41  39.12  2.59  78.90   \n",
      "2013-02-11  102.62  34.26  35.85  35.85  73.07  13.57  38.64  2.67  78.39   \n",
      "2013-02-12  103.46  34.30  35.42  35.42  73.37  13.51  38.89  2.77  78.60   \n",
      "2013-02-13  102.86  34.46  35.27  35.27  73.56  13.73  38.81  2.75  78.97   \n",
      "2013-02-14  102.78  34.70  36.57  36.57  73.13  14.00  38.61  2.75  78.84   \n",
      "\n",
      "              AES  ...    WLTW    WYNN    XEL    XRX   XLNX    XYL    YUM  \\\n",
      "date               ...                                                      \n",
      "2013-02-08  11.07  ...     NaN  126.52  27.84  31.84  37.51  27.09  65.30   \n",
      "2013-02-11  11.20  ...     NaN  124.10  27.94  31.96  37.46  27.46  64.55   \n",
      "2013-02-12  11.31  ...     NaN  122.67  28.00  31.84  37.58  27.95  64.75   \n",
      "2013-02-13  11.34  ...     NaN  122.40  27.92  32.00  37.80  28.26  64.41   \n",
      "2013-02-14  11.21  ...     NaN  123.20  27.89  32.12  38.44  28.47  63.89   \n",
      "\n",
      "              ZBH   ZION    ZTS  \n",
      "date                             \n",
      "2013-02-08  75.85  24.14  33.05  \n",
      "2013-02-11  75.65  24.21  33.26  \n",
      "2013-02-12  75.44  24.49  33.74  \n",
      "2013-02-13  76.00  24.74  33.55  \n",
      "2013-02-14  76.34  24.63  33.27  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    }
   ],
   "source": [
    "def compile_sp500_close_kaggle(reload_sp500=True):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_companies()        \n",
    "    else:\n",
    "        with open('sp500tickers.pickle', 'rb') as f:\n",
    "            tickers = pickle.load(f)\n",
    "    prices = []\n",
    "    prices_df = pd.DataFrame()\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        if (count %10 == 0):\n",
    "            print(count) #show progress\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv('individual_stocks_5yr/{}_data.csv'.format(ticker), index_col=0)\n",
    "            df = df.rename(columns={'close': ticker})\n",
    "            df = df[ticker]\n",
    "        except Exception as e:\n",
    "            print('{} not loaded'.format(ticker), e)\n",
    "        \n",
    "        prices.append(df)\n",
    "        prices_df = pd.concat([prices_df, df], axis=1)\n",
    "        \n",
    "    print(prices_df.head())\n",
    "    prices_df.to_csv('sp500_close_joined.csv')\n",
    "compile_sp500_close_kaggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
